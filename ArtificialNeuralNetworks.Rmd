```{r prologue, include=FALSE}
# connected to internet?
connected <- FALSE

library(knitr) # pull in the code file
read_chunk("Neuralnet1.R")

# chunk options
knitr::opts_chunk$set(warning = FALSE
                      , message = FALSE
                      , echo = FALSE
                      )

# figure options
knitr::opts_template$set(
  fig.standard = list(fig.height = 4, fig.width = 6, fig.align='center')
  , fig.relaxed = list(fig.height = 6, fig.width = 8, fig.align='center')
)
par(mar = c(4,3,3,1))
```

```{r load_libraries}
```

# Artificial Neural Networks in R  

#####Julian Hatwell
#####`r format(Sys.time(), "%b %Y")`
## Introduction  

This is a personal project with the objective of learning about Artificial Neural Networks (ANN) and their implementation in R.

All the code is available in my [github repo for statistical learning studies](https://github.com/julianhatwell/Statistical_Learning_Basics). Please take a look at the files named neuralnet*

A basic, succinct and clear explanation of how ANNs wok can be found at [Portilla,  (2016)](https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/), which I paraphrase here:

Neural networks are built from units called perceptrons (ptrons). Ptrons have one or more inputs, an activation function and an output. An ANN model is built up by combining ptrons in structured layers. The ptrons in a given layer are independent of each other, but the each connect to all the ptrons in the next layer.

* The input layer contains a ptron for each predictor variable
* One or more hidden layers contain a user defined number of ptrons. Each ptron in the first hidden layer receives an input from the each ptron in the input layer. If there is a second hidden layer, each ptron in this layer receives an input from each ptron in the first hidden layer, and so on with additional layers
* The output layer contains a ptron for each response variable (usually one, sometimes more in multivariate response situations). Each output ptron receives one input from each ptron in the final hidden layer
* The ptrons have a nonlinear activation function (e.g a logistic function) which determines their output value based upon the values of their inputs.

The connections between ptrons are weighted. The magnitude of the weight controls the strength of the influence of that input on the receiving ptron. The sign of the weight controls whether the influence is stimulating or inhibiting the signal to the next layer. 

The weights are somewhat analogous to the coefficients of a linear model. There is also a bias adjustment that represents the base Value of a ptron and is analogous to the intercept in a linear model. If the inputs are near zero, the bias ensures that the output is near average. However the situation is much more complex due to the network-like nature of the ANN. This leads to complex, non-linear relationships between the predictors and response.

There are a handful of interesting libraries though in this report I'll focus on the neuralnet package, [Fritsch & Guenther,  (2016)](https://CRAN.R-project.org/package=neuralnet).

[Hasheminia, (2015)](https://www.youtube.com/watch?v=lTMqXSSjCvk) provides a very useful introduction, covering the essential parameters and common steps.

This library is very flexible, allowing the analyst to build ANNs using a number of algorithms, activation functions and error functions and with multiple hidden layers to cover all but the most esoteric scenarios. It has syntax that is not entirely aligned with other model fitting libraries and functions so requires a couple of minor tweaks compared to common modeling functions, e.g. lm and glm.

This example uses the Boston data from the MASS package which contains a number of predictors of median property values in suburbs of Boston, MA, USA. See help(Boston) for more information. The code used is based on [Alice, (2015)](https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/) and adapted to emphasise and deepen particular topics.

```{r Boston_data, echo=TRUE, opts.label='fig.standard'}
```

It looks like the predictors tax and rad are highly correlated at > 80%. This can be a problem in some machine learning scenarios but I'm going to ignore it as that's not the focus of this report.

## Linear Model with Ordinary Least Squares

For the purposes of comparison, [Alice, (2015)](https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/) creates a linear model with ordinary least squares (OLS), which I reproduce here.

```{r glm_fit}
```

## ANN Model fits with neuralnet Library

I'll fit two models for comparison. The first has two hidden layers, with 5 and 3 ptrons, respectively. The second will have just one layer with 8 ptrons. One of the reasons for doing this is that some of the available utilities for analysing ANNs don't work with multiple hidden layers. This is by design in some cases but not easy to explain in others.

As a part of this project, I have created some new tools to get around this limitation.

Code is echoed to show a couple of quirks of the neuralnet library, namely the requirement to give a fully qualified formula. It is also necessary to scale the response variable to values falling between [0..1] and the predictor variables to z-scores $\sim{N(0, 1)}$ as discussed in [Olden & Jackson, (2002)](ftp://gis.msl.mt.gov/Maxell/Models/Predictive_Modeling_for_DSS_Lincoln_NE_121510/Modeling_Literature/Olden_ANN's.pdf). 

Other than that, the default settings are used for algorithm (rprop+ = resilient back propagation) and error function (sse = sum of squared errors). See R help(neuralnet) for further details on default settings.

The number of ptrons in the hidden layers is given as a numeric vector and the linear.output is set to TRUE, indicating a regression problem.

```{r neuralnet_fit, echo=TRUE}
```

To create performance metrics for comparison with the OLS model it's necessary to reversing the scaling operation on the responses/predictions. I won't echo that code here as it's visible in the github repository.

I use a utility function to generate Mean Squared Error (MSE), Route Mean Squared Error (RMSE) and Median Absolute Deviation (MAD).

The RMSE and MAD are both on the same scale as the errors and therefore somewhat easier to interpret than the MSE. Large differences between RMSE and MAD are indicitive of skew in the distribution of errors.

```{r performance_metrics}
```

Both ANN models are quite a lot better at predicting on new data than the OLS model. Though the two-layer model appears to do moderately better. This is expected due its greater flexibility/non-linearity. Some further analysis can be done to determine the better of the two more definitively (see later section on Cross Validation).

The difference between RMSE and MAD for all three models indicates that the errors are skewed. The majority of errors must be smaller than the mean error, implying that there are a small number of large outliers. 

## Visualising the ANN

Now that the two models have been trained it is possible to visualise them in a plot. The neuralnet library comes with a default plot function:

```{r include_plot, opts.label='fig.standard'}
# plot.nn doesn't want to appear in knitr
knitr::include_graphics(c("plot53nn.png", "plot8nn.png"))
```

[Beck, (2013)](https://beckmw.wordpress.com/2013/11/14/visualizing-neural-networks-in-r-update/) describes these plots as "leav[ing] much to be desired," and I tend to agree. These plots are difficult to work with. Visually they suffer from a problem of serious clutter, making the interation weights mostly illegible. In addition, the plot.nn function has some undesirable behaviour. In the RStudio environment, the plots appear as pop-outs rather than in the integrated viewer window. The function also doesn't seem to be compatible with knitr, so the images above were exported manually and included as static .png files. 

This issue has been addressed by the Neural Interpretation Diagram (NID) described in [Olden & Jackson, (2002)](ftp://gis.msl.mt.gov/Maxell/Models/Predictive_Modeling_for_DSS_Lincoln_NE_121510/Modeling_Literature/Olden_ANN's.pdf) and implemented in the NeuralNetTools library, [Beck, (2015)](http://CRAN.R-project.org/package=NeuralNetTools) as the plotnet() function. This gives the following default plots for the same models.

```{r nn_model_NNTools_plots, opts.label='fig.relaxed'}
```

This elegant plot solves the visual clutter problem by using line thickness to represent weight magnitude and line colour to represent weight sign (black = positive, grey = negative). Other useful features include a colour option for the input layer so that, for example, variable importance can be represented. This will be discussed next.

## Determining variable importance

ANNs have been attributed as having "superior predictive power" while being labelled a "black box" in the same article [Olden & Jackson, (2002)](ftp://gis.msl.mt.gov/Maxell/Models/Predictive_Modeling_for_DSS_Lincoln_NE_121510/Modeling_Literature/Olden_ANN's.pdf). This is because complex interactions can be modelled by the ANN giving highly flexible non-linear response values while this very flexibility  complicates the assessment of the relative importance of each predictor.

Several approaches for illiminating the mechanics of the models are described and compared by [Olden & Jackson, (2002)](ftp://gis.msl.mt.gov/Maxell/Models/Predictive_Modeling_for_DSS_Lincoln_NE_121510/Modeling_Literature/Olden_ANN's.pdf), [Gevrey et al, (2003)](http://www.sciencedirect.com/science/article/pii/S0304380002002570) and further discussed in [Olden et al, (2004)](http://www.sciencedirect.com/science/article/pii/S0304380004001565). The approach used in the NeuralNetTools library [Beck, (2015)](http://CRAN.R-project.org/package=NeuralNetTools) is Garson's algorithm in the garson() function. The resultant plot is shown next, although the garson() function in the NeuralNetTools library also only works for single layer models.

```{r nn_model_NNTools_varimp, echo=TRUE,  opts.label='fig.standard'}
```

Garson's algorithm was found by [Olden et al, (2004)](http://www.sciencedirect.com/science/article/pii/S0304380004001565) to be the least reliable method when tested against simulated data. They proposed a number of more reliable approaches. Their preferred option being to calculate the product of the weights through the model from each predictor to the output. I endeavour to create this as a custom function in R which works for any number of hidden layers. I also produce a simplified version that tallies the values of the input layer weights only.

I use the lattice plotting system rather than ggplot2 as this is my preference. I also opt for a dotplot, which better represents comparison of point values. According to Sarkar, (2008) barcharts are better reserved for counts, lengths or measures where the information is encoded in the height or area of the bar.

```{r nn_model_custom_varimp_w,  opts.label='fig.standard'}
```

Comparing these plots one is immediately struck by the inconsistency in both the ranking and sign of the variable effects with respect to each other. Intuitively one would expect generally similar results but these models have little in common.

## Model Profiling

An empirical approachto this problem is to use profiling which also has the benefit of illuminating the non-linear relationships of each predictor to the response and to each other.

The lekprofile method is broadly similar an the effect plot and describe in Gevrey et al(2003). This method has been devised with ANN in mind but could systematically be used with any multivariate problem.

In essence, a profiling method uses the generated/learned model to predict new values modifying one predictor through its full range while holding all but one of the predictors level. This is repeated at various levels the static predictors (e.g. quanstandards) and then iterated for all predictors (or simply those of interest).

The resulting graphs yield a fascinating insight on the model behaviour.

I've had trouble getting the NNT library lekprofile function to run with this data. It's also documented as not working for multiple hidden layers. 

```{r nn_model_NNTools_profile, echo=TRUE}
```

However, given the description of its implementation, I see no reason why it can't be run for multiple hidden layer models. Consequently I've also produced my own version of this plotting function using the lattice graphics system.

```{r nn_model_custom_profile,   opts.label='fig.relaxed'}
```

An interesting side effect of calculating all the individual predictor effects in this way is that the resulting range of response values gives a novel measure of variable importance.

With this in mind I have constructed a new plot that shows the magnitude of the response range as each predictor is applied through its full range, while holding the other variables at their minima, maxima and whichever level gives the individual predictor its strongest effect (it's not always the min or max of the others).

Here a barchart makes sense as we're comparing spans. Namely, the range of the response when the individual predictor is run through its range.

```{r nn_model_varimp_p,   opts.label='fig.relaxed'}
```

The results differ again from the Garson and weights accumulation methods. This plot is insightful because it's possible to see which variables are only important when other variables are at a minimum and which are still important with all the variables saturated. The interactions between variables is very apparent. Also interesting are the different profiles of variables. Some are unaffected by changes in the other predictors, some are highly suppressed or have vastly different curves with the others at the maxima, for example.

The most interesting ones can be plotted individually for futher examination.

```{r nn_model_custom_profile_indiv,   opts.label='fig.standard'}
```

There is a general weights plot function, gwplot delivers an individual profile plot but it's rather basic and doesn't have the richness of information as the lekprofile approach.

```{r nn_gwplot, opts.label='fig.standard'}
```

Using the variable importance based on the profiled range of values of the response as a result of each predictor, these values can be fed back into the NID plot of the NeuralNetTools function as below. Note that I find it more intuitive in this plot if darker colours model more important variables. This is contrary to the implementation of the garson algorithm for variable importance plot.

```{r nn_varimp_p_colour_plot, opts.label='fig.relaxed'}
```

## Model Performance

A common fitted versus actual, and fitted versus residual plots are as useful for visually comparing model performance. Plotting separately or together can help to diagnose the differences.

```{r pred_fitted_plots, opts.label='fig.relaxed'}
```

The ANN model with a single hidden layer looks to have the best performance based on how close the points are to the unity line. 

```{r pred_resid_plots, opts.label='fig.relaxed'}
```

## Cross validation to find best model

A more rigourous approach to determining model performance is considered good/best practice. The previous plots give a sense that these neuralnet models are better than OLS but how to tell between them? It's also understood from the literature (see references) that ANNs are very sensitive to the training data and simply changing the random seed could yield quite different results. The way to examine which model gives the best predictions is cross validation.

This process is a cinch with a linear model fit thanks to the boot library. For comparison, this process is run next.

```{r cross_validation_lm, echo=TRUE}
```

There is not, to my knowledge a similar library for the nn class of objects, so cross validati
on is hand-coded, using a standard pattern.

```{r cross_validation_nn, echo=TRUE}
```

```{r cross_validation_nn_results}
```

These results can be visualised to understand them more clearly.

```{r cross_validation_results_plot, opts.label='fig.relaxed'}
```

A t-test can be used to determine if the test results are significant:

```{r cross_validation_results_ttest, echo=TRUE}
```

The 95% confidence intervals from the t-tests contain zero both cases. From this result we can say that the differences in the means of the minimised loss functions (RMSE and MAD) do not yield significantly different results between the two models. The performance of both models is about the same, despite the early indications that the 2 hidden layer model was better.

It cannot escape my attention when using cross validation that OLS seems also to have faired about the same even though the literature suggests that in many cases ANNs are much more powerful algorithms.

## Conclusion

In this report I have explored the neuralnet and NeuralNetTools libraries by adapting some excellent code examples available on public blogs. I have also created some potentially useful diagnostic and exploratory tools of my own.

Despite my ambiguous results comparing to traditional OLS, the literature rates ANNs as one of the most useful and exciting machine learning algorithms which I will continue to use in my own work.

## References
Portilla, J. (2016), A Beginner’s Guide to Neural Networks with R! Available at: https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/ [Accessed September 2016]

Fritsch, S & Guenther, F. (2016).
'neuralnet: Training of Neural Networks' R
package version 1.33 Available at:
https://CRAN.R-project.org/package=neuralnet [Accessed September 2016]

Hamed, H (2015). 'R-Session 11 - Statistical Learning - Neural Networks' Available at:  https://www.youtube.com/watch?v=lTMqXSSjCvk [Accessed September 2016]

Michy, A. (2015). 'Fitting a neural network in R; neuralnet package' Available at: https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/ [Accessed September 2016]

Beck, M. (2015). 'NeuralNetTools: Visualization
and Analysis Tools for Neural Networks' R
package version 1.4.0 Available at: http://CRAN.R-project.org/package=NeuralNetTools [Accessed September 2016]

Beck, M. (2013). 'Visualizing neural networks in R – update' Available at: https://beckmw.wordpress.com/tag/neural-network/ [Accessed September 2016]

Julian D. Olden & Donald A. Jackson (2002). 'Illuminating the ‘‘black box’’: a randomization approach for understanding variable contributions in artificial neural networks' *Ecological Modelling* 154 pp. 135–150

Julian D. Olden, Michael K. Joy and Russell G. Death (2004). 'An accurate comparison of methods for quantifying variable importance in
artificial neural networks using simulated data' *Ecological Modelling* 178 pp. 389–397

Deepayan Sarkar (2008), Multivariate Data Visualization with R, Seattle: Springer, 2nd Printing p. 57

Gevrey, M., Dimopoulos, I., Lek, S. (2003). 'Review and comparison of methods to study the contribution of variables in artificial neural network models' *Ecological Modelling* 160, pp 249-264